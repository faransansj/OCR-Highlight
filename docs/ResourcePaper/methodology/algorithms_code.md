# í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ ë° ì½”ë“œ (Core Algorithms and Code)

## ğŸ¨ í•˜ì´ë¼ì´íŠ¸ ê²€ì¶œ ì•Œê³ ë¦¬ì¦˜ (Highlight Detection)

### Algorithm 1: HSV ìƒ‰ê³µê°„ ê¸°ë°˜ í•˜ì´ë¼ì´íŠ¸ ê²€ì¶œ

**ì•Œê³ ë¦¬ì¦˜ ì„¤ëª…**:
```
Input: RGB ì´ë¯¸ì§€ I, HSV ìƒ‰ìƒ ë²”ìœ„ R = {yellow, green, pink}
Output: ë°”ìš´ë”© ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸ B = {bâ‚, bâ‚‚, ..., bâ‚™}

1. I_hsv â† RGB_to_HSV(I)
2. For each color c in R:
    a. mask_c â† create_mask(I_hsv, R[c].lower, R[c].upper)
    b. mask_c â† gaussian_blur(mask_c, kernel_size=5)
    c. mask_c â† morphology_close(mask_c, kernel=ellipse(5,5), iterations=2)
    d. contours_c â† find_contours(mask_c)
    e. For each contour cnt in contours_c:
        i. If area(cnt) < min_area (120): skip
        ii. bbox â† bounding_box(cnt)
        iii. B â† B âˆª {bbox, color=c}
3. Return B
```

**ìˆ˜í•™ì  ëª¨ë¸**:

**HSV ë³€í™˜**:
```
H = arctan2(âˆš3(G - B), 2R - G - B)
S = 1 - 3 Ã— min(R,G,B) / (R + G + B)
V = (R + G + B) / 3
```

**ë§ˆìŠ¤í¬ ìƒì„±**:
```
M(x,y) = { 1  if L_h â‰¤ H(x,y) â‰¤ U_h AND
                L_s â‰¤ S(x,y) â‰¤ U_s AND
                L_v â‰¤ V(x,y) â‰¤ U_v
           0  otherwise
```

**ë‹«í˜ ì—°ì‚° (Morphological Closing)**:
```
Close(M) = Erode(Dilate(M, K), K)
```
where K = elliptical structuring element (5Ã—5)

### ì‹¤ì œ ì½”ë“œ êµ¬í˜„

```python
def detect_highlights(image: np.ndarray,
                      hsv_ranges: Dict[str, Dict],
                      min_area: int = 120) -> List[Dict]:
    """
    HSV ìƒ‰ê³µê°„ ê¸°ë°˜ í•˜ì´ë¼ì´íŠ¸ ê²€ì¶œ

    Args:
        image: RGB ì´ë¯¸ì§€ (HÃ—WÃ—3)
        hsv_ranges: ìƒ‰ìƒë³„ HSV ë²”ìœ„
            {
                'yellow': {'lower': [25,60,70], 'upper': [35,255,255]},
                'green':  {'lower': [55,60,70], 'upper': [65,255,255]},
                'pink':   {'lower': [169,10,70], 'upper': [180,70,255]}
            }
        min_area: ìµœì†Œ ì˜ì—­ í¬ê¸° (í”½ì…€Â²)

    Returns:
        ê²€ì¶œëœ í•˜ì´ë¼ì´íŠ¸ ë¦¬ìŠ¤íŠ¸
        [
            {
                'bbox': {'x': int, 'y': int, 'width': int, 'height': int},
                'color': str,
                'area': float
            },
            ...
        ]
    """
    # 1. RGB â†’ HSV ë³€í™˜
    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

    # 2. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ (ë…¸ì´ì¦ˆ ì œê±°)
    blurred = cv2.GaussianBlur(hsv_image, (5, 5), 0)

    detections = []

    # 3. ê° ìƒ‰ìƒë³„ ì²˜ë¦¬
    for color, ranges in hsv_ranges.items():
        # 3a. ìƒ‰ìƒ ë§ˆìŠ¤í¬ ìƒì„±
        lower = np.array(ranges['lower'])
        upper = np.array(ranges['upper'])
        mask = cv2.inRange(blurred, lower, upper)

        # 3b. í˜•íƒœí•™ì  ë‹«í˜ ì—°ì‚°
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)

        # 3c. ìœ¤ê³½ì„  ê²€ì¶œ
        contours, _ = cv2.findContours(
            mask,
            cv2.RETR_EXTERNAL,
            cv2.CHAIN_APPROX_SIMPLE
        )

        # 3d. ìœ¤ê³½ì„  í•„í„°ë§ ë° ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ì¶œ
        for contour in contours:
            area = cv2.contourArea(contour)

            # ìµœì†Œ ë©´ì  í•„í„°
            if area < min_area:
                continue

            # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
            x, y, w, h = cv2.boundingRect(contour)

            # ì¢…íš¡ë¹„ í•„í„° (0.2 ~ 20)
            aspect_ratio = w / h if h > 0 else 0
            if aspect_ratio < 0.2 or aspect_ratio > 20:
                continue

            # ê²½ê³„ í•„í„° (ì´ë¯¸ì§€ ê°€ì¥ìë¦¬ 5px ì´ë‚´ ì œì™¸)
            h_img, w_img = image.shape[:2]
            if x < 5 or y < 5 or x + w > w_img - 5 or y + h > h_img - 5:
                continue

            detections.append({
                'bbox': {'x': x, 'y': y, 'width': w, 'height': h},
                'color': color,
                'area': area
            })

    return detections
```

### HSV ë²”ìœ„ ìµœì í™” (ê·¸ë¦¬ë“œ ì„œì¹˜)

```python
def optimize_hsv_ranges(images: List[np.ndarray],
                        ground_truth: List[List[Dict]],
                        color: str) -> Dict[str, List[int]]:
    """
    ê·¸ë¦¬ë“œ ì„œì¹˜ë¥¼ í†µí•œ HSV ë²”ìœ„ ìµœì í™”

    Args:
        images: í›ˆë ¨ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
        ground_truth: ê° ì´ë¯¸ì§€ì˜ GT ë°”ìš´ë”© ë°•ìŠ¤
        color: ìµœì í™”í•  ìƒ‰ìƒ

    Returns:
        ìµœì  HSV ë²”ìœ„ {'lower': [h,s,v], 'upper': [h,s,v]}
    """
    best_miou = 0.0
    best_range = None

    # ìƒ‰ìƒë³„ íƒìƒ‰ ë²”ìœ„
    if color == 'yellow':
        h_search = range(20, 40, 5)
    elif color == 'green':
        h_search = range(50, 70, 5)
    elif color == 'pink':
        h_search = range(165, 180, 5)

    s_search = range(40, 100, 20)
    v_search = range(50, 100, 20)

    # ê·¸ë¦¬ë“œ ì„œì¹˜
    for h_min in h_search:
        for s_min in s_search:
            for v_min in v_search:
                # ë²”ìœ„ ì •ì˜
                lower = [h_min, s_min, v_min]
                upper = [h_min + 10, 255, 255]

                # ì „ì²´ ì´ë¯¸ì§€ì— ëŒ€í•´ í‰ê°€
                ious = []
                for img, gt in zip(images, ground_truth):
                    detections = detect_highlights(
                        img,
                        {color: {'lower': lower, 'upper': upper}}
                    )
                    iou = calculate_miou(detections, gt)
                    ious.append(iou)

                # í‰ê·  mIoU ê³„ì‚°
                miou = np.mean(ious)

                # ìµœì ê°’ ì—…ë°ì´íŠ¸
                if miou > best_miou:
                    best_miou = miou
                    best_range = {'lower': lower, 'upper': upper}

    print(f"{color} ìµœì  ë²”ìœ„: {best_range}, mIoU: {best_miou:.4f}")
    return best_range
```

---

## ğŸ” OCR ì•Œê³ ë¦¬ì¦˜ (Text Extraction)

### Algorithm 2: ë‹¤ì¤‘ PSM ëª¨ë“œ OCR

**ì•Œê³ ë¦¬ì¦˜ ì„¤ëª…**:
```
Input: ì´ë¯¸ì§€ ì˜ì—­ R, ì‹ ë¢°ë„ ì„ê³„ê°’ Ï„ (default: 70%)
Output: í…ìŠ¤íŠ¸ T, ì‹ ë¢°ë„ C

1. (Tâ‚€, Câ‚€) â† tesseract_ocr(R, psm=7)  // ë‹¨ì¼ ë¼ì¸ ëª¨ë“œ

2. If Câ‚€ â‰¥ Ï„:
    Return (Tâ‚€, Câ‚€)

3. Else:  // Multi-PSM fallback
    results â† []
    For psm in [3, 8, 11]:  // ì™„ì „ ìë™, ë‹¨ì¼ ë‹¨ì–´, í¬ì†Œ í…ìŠ¤íŠ¸
        (T_i, C_i) â† tesseract_ocr(R, psm)
        results.append((T_i, C_i))

    // ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ ì„ íƒ
    (T_best, C_best) â† argmax(results, key=confidence)
    Return (T_best, C_best)
```

### ì‹¤ì œ ì½”ë“œ êµ¬í˜„

```python
def extract_text_with_multi_psm(image: np.ndarray,
                                 bbox: Dict[str, int],
                                 lang: str = 'kor+eng',
                                 min_confidence: float = 70.0) -> Tuple[str, float]:
    """
    ë‹¤ì¤‘ PSM ëª¨ë“œë¥¼ ì‚¬ìš©í•œ OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ

    Args:
        image: ì…ë ¥ ì´ë¯¸ì§€
        bbox: ë°”ìš´ë”© ë°•ìŠ¤ {'x', 'y', 'width', 'height'}
        lang: OCR ì–¸ì–´ ('kor+eng' for í•œê¸€+ì˜ë¬¸)
        min_confidence: Multi-PSM í™œì„±í™” ì„ê³„ê°’

    Returns:
        (ì¶”ì¶œ í…ìŠ¤íŠ¸, í‰ê·  ì‹ ë¢°ë„)
    """
    # 1. ROI ì˜ì—­ ì¶”ì¶œ
    x, y, w, h = bbox['x'], bbox['y'], bbox['width'], bbox['height']
    roi = image[y:y+h, x:x+w]

    # 2. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    if len(roi.shape) == 3:
        roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    else:
        roi_gray = roi

    # 3. ì£¼ ëª¨ë“œ: PSM 7 (ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¼ì¸)
    config_primary = f'--psm 7 --oem 3 -l {lang}'
    data = pytesseract.image_to_data(
        roi_gray,
        config=config_primary,
        output_type=pytesseract.Output.DICT
    )

    # í…ìŠ¤íŠ¸ ë° ì‹ ë¢°ë„ ì¶”ì¶œ
    text_primary = ' '.join([
        word for word, conf in zip(data['text'], data['conf'])
        if conf > 0 and word.strip()
    ])

    confidences = [
        conf for conf in data['conf']
        if conf > 0
    ]

    avg_conf_primary = np.mean(confidences) if confidences else 0.0

    # 4. ì‹ ë¢°ë„ ì²´í¬
    if avg_conf_primary >= min_confidence:
        return text_primary, avg_conf_primary

    # 5. Multi-PSM Fallback
    alternative_psms = [3, 8, 11]  # ì™„ì „ ìë™, ë‹¨ì¼ ë‹¨ì–´, í¬ì†Œ í…ìŠ¤íŠ¸
    results = [(text_primary, avg_conf_primary)]

    for psm in alternative_psms[:2]:  # ìƒìœ„ 2ê°œë§Œ ì‹œë„ (ì„±ëŠ¥ ê³ ë ¤)
        config_alt = f'--psm {psm} --oem 3 -l {lang}'
        data_alt = pytesseract.image_to_data(
            roi_gray,
            config=config_alt,
            output_type=pytesseract.Output.DICT
        )

        text_alt = ' '.join([
            word for word, conf in zip(data_alt['text'], data_alt['conf'])
            if conf > 0 and word.strip()
        ])

        confidences_alt = [
            conf for conf in data_alt['conf']
            if conf > 0
        ]

        avg_conf_alt = np.mean(confidences_alt) if confidences_alt else 0.0
        results.append((text_alt, avg_conf_alt))

    # 6. ìµœê³  ì‹ ë¢°ë„ ê²°ê³¼ ì„ íƒ
    best_text, best_conf = max(results, key=lambda x: x[1])

    return best_text, best_conf
```

---

## âœ¨ í›„ì²˜ë¦¬ ì•Œê³ ë¦¬ì¦˜ (Post-processing)

### Algorithm 3: í•œêµ­ì–´ ê³µë°± ì œê±° (ì¬ê·€)

**ì•Œê³ ë¦¬ì¦˜ ì„¤ëª…**:
```
Input: OCR í…ìŠ¤íŠ¸ T
Output: í›„ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ T'

1. T_prev â† None
2. While T_prev â‰  T:
    a. T_prev â† T
    b. T â† replace(T, pattern="(í•œê¸€)\s+(í•œê¸€)", replacement="$1$2")
    c. T â† replace(T, pattern="(í•œê¸€)\s+(ì¡°ì‚¬)", replacement="$1$2")
3. Return T
```

**ìˆ˜í•™ì  ëª¨ë¸**:

**í•œê¸€ ìœ ë‹ˆì½”ë“œ ë²”ìœ„**:
```
Korean = [\uAC00-\uD7AF]  // ê°€-í£ (ì™„ì„±í˜• í•œê¸€ 11,172ì)
```

**ì¡°ì‚¬ ì§‘í•©**:
```
Particles = {ì€, ëŠ”, ì´, ê°€, ì„, ë¥¼, ì—ì„œ}
```

**ì •ê·œì‹ íŒ¨í„´**:
```
Patternâ‚ = (Korean)\s+(Korean)
Patternâ‚‚ = (Korean)\s+(Particle)\b
```

### ì‹¤ì œ ì½”ë“œ êµ¬í˜„

```python
def postprocess_korean_text(text: str) -> str:
    """
    í•œêµ­ì–´ í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

    í›„ì²˜ë¦¬ ìˆœì„œ:
    1. í•œêµ­ì–´ ê³µë°± ì œê±° (ì¬ê·€)
    2. ì¡°ì‚¬ ê³µë°± ì œê±°
    3. ì¤‘ë³µ í…ìŠ¤íŠ¸ ì œê±°
    4. í•œêµ­ì–´ ì¡°ì‚¬ ë³µì› (E â†’ ëŠ”)
    5. ë¬¸ì ì¹˜í™˜ ìˆ˜ì •
    6. ë…¸ì´ì¦ˆ ì œê±°

    Args:
        text: OCR ì›ë³¸ í…ìŠ¤íŠ¸

    Returns:
        í›„ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
    """
    import re

    # 0. ì•ë’¤ ê³µë°± ì œê±°
    text = text.strip()

    # 1. í•œêµ­ì–´ ê³µë°± ì œê±° (ì¬ê·€ì )
    prev_text = None
    while prev_text != text:
        prev_text = text
        # í•œê¸€ ë¬¸ì ê°„ ê³µë°± ì œê±°
        text = re.sub(r'([\uac00-\ud7af])\s+([\uac00-\ud7af])', r'\1\2', text)

    # 2. ì¡°ì‚¬ ì• ê³µë°± ì œê±°
    text = re.sub(
        r'([\uac00-\ud7af])\s+([ì€ëŠ”ì´ê°€ì„ë¥¼ì—ì„œ])\b',
        r'\1\2',
        text
    )

    # 3. ì¤‘ë³µ í…ìŠ¤íŠ¸ ì œê±°
    # íŒ¨í„´: "í•­ìŠµì„í•™ìŠµì„" â†’ "í•™ìŠµì„"
    matches = re.findall(r'([\uac00-\ud7af]{2,}[ì€ë¥¼ì„])', text)
    if len(matches) >= 2:
        for i, match1 in enumerate(matches):
            for match2 in matches[i+1:]:
                # match2ê°€ match1ë¡œ ëë‚˜ê³  ë” ê¸¸ë©´ ì œê±°
                if match2.endswith(match1) and len(match2) > len(match1):
                    text = text.replace(match2, match1, 1)

    # 4. í•œêµ­ì–´ ì¡°ì‚¬ ë³µì›
    # "OpenCVE" â†’ "OpenCVëŠ”" (Eê°€ ëŠ”ìœ¼ë¡œ ì˜¤ì¸ì‹)
    if text.endswith('E') and len(text) > 1:
        # ì˜ë¬¸ ë‹¨ì–´ + E íŒ¨í„´
        if re.match(r'^[A-Z][A-Za-z]+E$', text):
            text = text[:-1] + 'ëŠ”'

    # 5. ë¬¸ì ì¹˜í™˜ ìˆ˜ì • (ê³ ë¹ˆë„ ì˜¤ë¥˜)
    text = re.sub(r'Opencv', 'OpenCV', text)
    text = re.sub(r'OpencV', 'OpenCV', text)
    text = re.sub(r'OpencVE', 'OpenCVëŠ”', text)
    text = re.sub(r'Tesseracf', 'Tesseract', text)

    # 6. ë…¸ì´ì¦ˆ ì œê±°
    # 6a. í›„í–‰ ëŒ€ë¬¸ì ì²­í¬ ì œê±°: "í•™ìŠµì„ TSS" â†’ "í•™ìŠµì„"
    text = re.sub(
        r'([\uac00-\ud7af]+[ì€ëŠ”ì´ê°€ì„ë¥¼ì—ì„œ]?)\s+[A-Z]{2,}$',
        r'\1',
        text
    )

    # 6b. ë…ë¦½ ê¸°í˜¸ ì œê±°
    text = re.sub(r'\s+[|/:;.]+\s*$', '', text)

    # 6c. ê³¼ë¶„í•  ìˆ˜ì •: "Intersection over Union" â†’ "Intersection"
    if text.startswith('Intersection') and len(text) > len('Intersection'):
        # 'Intersection' ì´í›„ì— ì¶”ê°€ ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ì œê±°
        if ' ' in text[len('Intersection'):]:
            text = 'Intersection'

    # 7. ìµœì¢… ì •ë¦¬
    text = text.strip()

    return text
```

### Algorithm 4: ì¤‘ë³µ í…ìŠ¤íŠ¸ ì œê±°

**ìˆ˜ë„ì½”ë“œ**:
```
Input: í…ìŠ¤íŠ¸ T
Output: ì¤‘ë³µ ì œê±°ëœ í…ìŠ¤íŠ¸ T'

1. matches â† find_all(T, pattern="(í•œê¸€{2,}ì¡°ì‚¬)")
2. If |matches| < 2:
    Return T  // ì¤‘ë³µ ì—†ìŒ

3. For i = 0 to |matches| - 1:
    For j = i+1 to |matches| - 1:
        m1 â† matches[i]
        m2 â† matches[j]
        If m2.endswith(m1) AND |m2| > |m1|:
            T â† replace_first(T, m2, m1)

4. Return T
```

**ì‹¤ì œ ì½”ë“œ**:
```python
def remove_duplicate_korean_words(text: str) -> str:
    """
    ì¤‘ë³µëœ í•œêµ­ì–´ ë‹¨ì–´ ì œê±°

    ì˜ˆì‹œ:
        "í•­ìŠµì„í•™ìŠµì„" â†’ "í•™ìŠµì„"
        "ì¸ì‹ì€ì¸ì‹ì€" â†’ "ì¸ì‹ì€"

    Args:
        text: ì…ë ¥ í…ìŠ¤íŠ¸

    Returns:
        ì¤‘ë³µ ì œê±°ëœ í…ìŠ¤íŠ¸
    """
    import re

    # í•œê¸€ + ì¡°ì‚¬ íŒ¨í„´ ì°¾ê¸° (2ê¸€ì ì´ìƒ)
    pattern = r'([\uac00-\ud7af]{2,}[ì€ë¥¼ì„ì´ê°€ì—ì„œ]?)'
    matches = re.findall(pattern, text)

    if len(matches) < 2:
        return text  # ì¤‘ë³µ ê°€ëŠ¥ì„± ì—†ìŒ

    # ì¤‘ë³µ ê²€ì‚¬ ë° ì œê±°
    for i, match1 in enumerate(matches):
        for match2 in matches[i+1:]:
            # match2ê°€ match1ë¡œ ëë‚˜ê³  ë” ê¸¸ë©´ ì¤‘ë³µ
            if match2.endswith(match1) and len(match2) > len(match1):
                # ì²« ë²ˆì§¸ ë§¤ì¹­ë§Œ êµì²´ (ë‹¤ì¤‘ êµì²´ ë°©ì§€)
                text = text.replace(match2, match1, 1)

    return text
```

---

## ğŸ“ ì„±ëŠ¥ í‰ê°€ ë©”íŠ¸ë¦­ (Evaluation Metrics)

### Character Error Rate (CER)

**ìˆ˜ì‹**:
```
CER = (S + D + I) / N

where:
    S = ì¹˜í™˜ ì˜¤ë¥˜ ìˆ˜ (Substitutions)
    D = ì‚­ì œ ì˜¤ë¥˜ ìˆ˜ (Deletions)
    I = ì‚½ì… ì˜¤ë¥˜ ìˆ˜ (Insertions)
    N = Ground Truth ì´ ë¬¸ì ìˆ˜
```

**ì½”ë“œ êµ¬í˜„**:
```python
def calculate_cer(reference: str, hypothesis: str) -> float:
    """
    Character Error Rate ê³„ì‚° (Levenshtein Distance ê¸°ë°˜)

    Args:
        reference: Ground Truth í…ìŠ¤íŠ¸
        hypothesis: ì˜ˆì¸¡ í…ìŠ¤íŠ¸

    Returns:
        CER (0.0 ~ 1.0)
    """
    import Levenshtein

    # Levenshtein ê±°ë¦¬ ê³„ì‚°
    distance = Levenshtein.distance(reference, hypothesis)

    # CER ê³„ì‚°
    cer = distance / len(reference) if len(reference) > 0 else 0.0

    return cer


def calculate_detailed_cer(reference: str, hypothesis: str) -> Dict:
    """
    ìƒì„¸ CER ê³„ì‚° (ì˜¤ë¥˜ ìœ í˜•ë³„ ë¶„ë¥˜)

    Returns:
        {
            'cer': float,
            'substitutions': int,
            'deletions': int,
            'insertions': int,
            'total_errors': int,
            'total_chars': int
        }
    """
    import Levenshtein

    # Levenshtein í¸ì§‘ ì—°ì‚° ì¶”ì¶œ
    ops = Levenshtein.editops(reference, hypothesis)

    substitutions = sum(1 for op in ops if op[0] == 'replace')
    deletions = sum(1 for op in ops if op[0] == 'delete')
    insertions = sum(1 for op in ops if op[0] == 'insert')

    total_errors = len(ops)
    total_chars = len(reference)
    cer = total_errors / total_chars if total_chars > 0 else 0.0

    return {
        'cer': cer,
        'substitutions': substitutions,
        'deletions': deletions,
        'insertions': insertions,
        'total_errors': total_errors,
        'total_chars': total_chars
    }
```

### mean Intersection over Union (mIoU)

**ìˆ˜ì‹**:
```
IoU = Area(Prediction âˆ© Ground Truth) / Area(Prediction âˆª Ground Truth)

mIoU = (1/N) Ã— Î£ IoU_i
```

**ì½”ë“œ êµ¬í˜„**:
```python
def calculate_iou(bbox1: Dict, bbox2: Dict) -> float:
    """
    ë‘ ë°”ìš´ë”© ë°•ìŠ¤ ê°„ IoU ê³„ì‚°

    Args:
        bbox1, bbox2: {'x', 'y', 'width', 'height'}

    Returns:
        IoU (0.0 ~ 1.0)
    """
    # ì¢Œí‘œ ì¶”ì¶œ
    x1_min = bbox1['x']
    y1_min = bbox1['y']
    x1_max = x1_min + bbox1['width']
    y1_max = y1_min + bbox1['height']

    x2_min = bbox2['x']
    y2_min = bbox2['y']
    x2_max = x2_min + bbox2['width']
    y2_max = y2_min + bbox2['height']

    # êµì§‘í•© ì˜ì—­ ê³„ì‚°
    x_inter_min = max(x1_min, x2_min)
    y_inter_min = max(y1_min, y2_min)
    x_inter_max = min(x1_max, x2_max)
    y_inter_max = min(y1_max, y2_max)

    # êµì§‘í•©ì´ ì—†ìœ¼ë©´ IoU = 0
    if x_inter_max < x_inter_min or y_inter_max < y_inter_min:
        return 0.0

    inter_area = (x_inter_max - x_inter_min) * (y_inter_max - y_inter_min)

    # í•©ì§‘í•© ì˜ì—­ ê³„ì‚°
    area1 = bbox1['width'] * bbox1['height']
    area2 = bbox2['width'] * bbox2['height']
    union_area = area1 + area2 - inter_area

    # IoU ê³„ì‚°
    iou = inter_area / union_area if union_area > 0 else 0.0

    return iou


def calculate_miou(predictions: List[Dict],
                   ground_truths: List[Dict],
                   iou_threshold: float = 0.5) -> float:
    """
    mean IoU ê³„ì‚° (í—ê°€ë¦¬ì•ˆ ë§¤ì¹­ ì‚¬ìš©)

    Args:
        predictions: ì˜ˆì¸¡ ë°”ìš´ë”© ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸
        ground_truths: GT ë°”ìš´ë”© ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸
        iou_threshold: ë§¤ì¹­ ì„ê³„ê°’

    Returns:
        mIoU (0.0 ~ 1.0)
    """
    if len(ground_truths) == 0:
        return 1.0 if len(predictions) == 0 else 0.0

    # IoU ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
    iou_matrix = np.zeros((len(predictions), len(ground_truths)))

    for i, pred in enumerate(predictions):
        for j, gt in enumerate(ground_truths):
            iou_matrix[i, j] = calculate_iou(pred['bbox'], gt['bbox'])

    # í—ê°€ë¦¬ì•ˆ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìµœì  ë§¤ì¹­
    from scipy.optimize import linear_sum_assignment
    row_ind, col_ind = linear_sum_assignment(-iou_matrix)

    # ë§¤ì¹­ëœ IoU í•©ê³„
    matched_ious = []
    for i, j in zip(row_ind, col_ind):
        if iou_matrix[i, j] >= iou_threshold:
            matched_ious.append(iou_matrix[i, j])

    # mIoU ê³„ì‚°
    miou = np.mean(matched_ious) if matched_ious else 0.0

    return miou
```

---

## ğŸ§ª ì‹¤í—˜ ì¬í˜„ ì½”ë“œ (Reproducibility)

### ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

```python
def run_full_pipeline(image_path: str,
                      config_path: str = 'configs/optimized_hsv_ranges.json',
                      output_dir: str = 'outputs/extracted/') -> ExtractionResult:
    """
    ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì¬í˜„ì„± ë³´ì¥)

    Args:
        image_path: ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ
        config_path: HSV ì„¤ì • íŒŒì¼
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬

    Returns:
        ExtractionResult ê°ì²´
    """
    import json
    from pathlib import Path

    # 1. ì„¤ì • ë¡œë“œ
    with open(config_path, 'r') as f:
        config = json.load(f)

    # 2. ì´ë¯¸ì§€ ë¡œë“œ
    image = cv2.imread(image_path)
    if image is None:
        raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")

    # 3. Stage 1: í•˜ì´ë¼ì´íŠ¸ ê²€ì¶œ
    detections = detect_highlights(
        image,
        hsv_ranges=config['hsv_ranges'],
        min_area=config.get('min_area', 120)
    )

    print(f"ê²€ì¶œëœ í•˜ì´ë¼ì´íŠ¸: {len(detections)}ê°œ")

    # 4. Stage 2 & 3: OCR + í›„ì²˜ë¦¬
    results = []
    for det in detections:
        text, confidence = extract_text_with_multi_psm(
            image,
            bbox=det['bbox'],
            lang='kor+eng',
            min_confidence=60.0
        )

        # í›„ì²˜ë¦¬
        text = postprocess_korean_text(text)

        results.append({
            'text': text,
            'color': det['color'],
            'confidence': confidence,
            'bbox': det['bbox']
        })

    # 5. ê²°ê³¼ ê°ì²´ ìƒì„±
    extraction_result = {
        'image_path': image_path,
        'total_highlights': len(results),
        'highlights_by_color': count_by_color(results),
        'results': results
    }

    # 6. ì¶œë ¥ ì €ì¥
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    base_name = Path(image_path).stem

    # JSON ì €ì¥
    json_path = Path(output_dir) / f"{base_name}.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(extraction_result, f, ensure_ascii=False, indent=2)

    print(f"ê²°ê³¼ ì €ì¥: {json_path}")

    return extraction_result


def count_by_color(results: List[Dict]) -> Dict[str, int]:
    """ìƒ‰ìƒë³„ í•˜ì´ë¼ì´íŠ¸ ê°œìˆ˜"""
    counts = {'yellow': 0, 'green': 0, 'pink': 0}
    for r in results:
        counts[r['color']] += 1
    return counts
```

---

**ì•Œê³ ë¦¬ì¦˜ ë³µì¡ë„ ë¶„ì„**:

| ì•Œê³ ë¦¬ì¦˜ | ì‹œê°„ ë³µì¡ë„ | ê³µê°„ ë³µì¡ë„ | ë¹„ê³  |
|----------|-------------|-------------|------|
| HSV ê²€ì¶œ | O(NÃ—M) | O(NÃ—M) | NÃ—M = ì´ë¯¸ì§€ í¬ê¸° |
| ìœ¤ê³½ì„  ê²€ì¶œ | O(NÃ—M) | O(K) | K = ìœ¤ê³½ì„  ì  ê°œìˆ˜ |
| Tesseract OCR | O(WÃ—HÃ—D) | O(WÃ—H) | D = LSTM ê¹Šì´ |
| í›„ì²˜ë¦¬ (ì •ê·œì‹) | O(L) | O(L) | L = í…ìŠ¤íŠ¸ ê¸¸ì´ |
| **ì „ì²´** | **O(NÃ—M + WÃ—HÃ—D)** | **O(NÃ—M)** | OCRì´ ë³‘ëª© |

---

**ì¬í˜„ì„± ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [x] ëœë¤ ì‹œë“œ ê³ ì • (í•´ë‹¹ ì—†ìŒ - ê²°ì •ë¡ ì  ì•Œê³ ë¦¬ì¦˜)
- [x] ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ëª…ì‹œ (requirements.txt)
- [x] ì„¤ì • íŒŒë¼ë¯¸í„° ë¬¸ì„œí™” (configs/)
- [x] ë°ì´í„°ì…‹ ë¶„í•  ê³ ì • (train/val/test)
- [x] í‰ê°€ ë©”íŠ¸ë¦­ êµ¬í˜„ ëª…ì‹œ

**ì½”ë“œ ì €ì¥ì†Œ**: `/Users/midori/Research/Text-Highlight/`
**í•µì‹¬ íŒŒì¼**:
- `src/highlight_detector.py`
- `src/ocr/ocr_engine.py`
- `src/pipeline.py`
